% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/confusion_metrics.R
\name{confusion_metrics}
\alias{confusion_metrics}
\title{Confusion matrix and classification metrics for logistic models}
\usage{
confusion_metrics(y, prob, cutoff = 0.5)
}
\arguments{
\item{y}{Observed binary response. Can be:
\itemize{
  \item numeric (0/1),
  \item logical (\code{FALSE}/\code{TRUE}),
  \item factor with 2 levels (the second level is treated as "positive").
}}

\item{prob}{Numeric vector of predicted probabilities for the positive class,
of the same length as \code{y}.}

\item{cutoff}{Numeric cutoff in (0, 1) used to classify predictions as
positive; default is 0.5.}
}
\value{
A list with components:
  \item{confusion}{2x2 matrix with rows = observed (0/1), columns = predicted (0/1),
        in the order: 0 = negative, 1 = positive.}
  \item{metrics}{Named numeric vector with:
        \code{prevalence}, \code{accuracy}, \code{sensitivity},
        \code{specificity}, \code{FDR}, \code{DOR}.}
}
\description{
Computes a confusion matrix and standard classification metrics at a given
probability cutoff (default 0.5) for binary outcomes. This is mainly intended
for evaluating logistic regression models in the vignette.

The function expects observed binary outcomes \code{y} and predicted
probabilities \code{prob} for the positive class.
}
\details{
The metrics are defined as:
\itemize{
  \item \code{prevalence} = (TP + FN) / N
  \item \code{accuracy}   = (TP + TN) / N
  \item \code{sensitivity} (recall, TPR) = TP / (TP + FN)
  \item \code{specificity} (TNR) = TN / (TN + FP)
  \item \code{FDR} (false discovery rate) = FP / (TP + FP)
  \item \code{DOR} (diagnostic odds ratio) =
        (TP / FN) / (FP / TN) = (TP * TN) / (FP * FN)
}
When a denominator is zero (e.g. no positives, no predicted positives, or a
cell count is zero), the corresponding metric is returned as \code{NA}.
}
